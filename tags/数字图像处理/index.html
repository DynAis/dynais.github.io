<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>数字图像处理 | DynAis</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://dynais.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=icon href=https://dynais.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dynais.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dynais.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dynais.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dynais.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://dynais.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="数字图像处理"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://dynais.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><meta name=twitter:card content="summary"><meta name=twitter:title content="数字图像处理"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dynais.github.io/ accesskey=h title="DynAis (Alt + H)">DynAis</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><header class=page-header><h1>数字图像处理</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>使用差分散列的重复图片检测</h2></header><section class=entry-content><p>关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.
而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:
视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大 那么我们有以下几个Hash函数的选择:
差分散列(difference hashing) md5 sha-1 最终我们选择了差分散列的方法, 有以下的原因:
差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!) Detect and remove duplicate images from a dataset for deep learning 文章链接:
https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/
https://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb
前言:
为什么要删去数据集中重复的图片?
Having duplicate images in your dataset creates a problem for two reasons:
It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize....</p></section><footer class=entry-footer><span title="2020-04-22 00:00:00 +0000 UTC">April 22, 2020</span></footer><a class=entry-link aria-label="post link to 使用差分散列的重复图片检测" href=https://dynais.github.io/posts/nt-ocpy-%E4%BD%BF%E7%94%A8%E5%B7%AE%E5%88%86%E6%95%A3%E5%88%97%E6%A3%80%E6%B5%8B%E9%87%8D%E5%A4%8D%E5%9B%BE%E7%89%87/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记12-模板匹配</h2></header><section class=entry-content><p>API matchTemplate();//模式查找,API比较简单 minMaxLoc();//用于在模式查找的输出图像中找到极值点,也就是匹配点 笔记 模板匹配(Templet Match)
相当于上一节说的直方图匹配的实用化,通过现有图像在目标图像上滑行(原文Slide),也就是左到右上到下的以像素为单位进行匹配,找到匹配值最大的点.但也是因为这个原因,对模板图像和在目标图像里的目标的大小进行匹配就非常重要,如果大小差得远,效果就不好,所以使用条件相当苛刻.
注意输出图像的大小
在API中需要提供一个储存输出结果的Mat, 他的大小是
Size(src.cols-templ.cols+1, src.rows-templ.rows+1) OpenCV的查找模式
OpenCV提供了很多种方法,在官网上都有介绍,大部分都是取用了最大值作为最匹配
根据最小值匹配的只有 TM_SQDIFF 和 MT_SQDIFF_NORMED
For the first two methods ( TM_SQDIFF and MT_SQDIFF_NORMED ) the best match are the lowest values.
OpenCV中32位的图像
每个数值是一个位于[0,1]间的小数,相当于8位的[0,255]
源//API实现模式查找 // OpenCV_Template.cpp : 此文件包含 "main" 函数。程序执行将在此处开始并结束。 // #include &lt;iostream>#include&lt;opencv2\opencv.hpp> using namespace std; using namespace cv; Mat src, dst, temp; int main(int, char**) { temp = imread("D:/WorkSpace/Projects/OpenCV Learning/ImageHub/Lena....</p></section><footer class=entry-footer><span title="2020-02-20 00:00:00 +0000 UTC">February 20, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记12-模板匹配" href=https://dynais.github.io/posts/nt-oc-a12_%E6%A8%A1%E6%9D%BF%E5%8C%B9%E9%85%8D/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记11-直方图均衡化-直方图比较-反向投影</h2></header><section class=entry-content><p>API - equalizeHist();//直方图均衡化 - split();//分离通道 - calcHist();//参数dims,bin,range - waitkey(); - mixChannels//分离通道, 与split小有差别,建议看官方文档 - cvtColer//使用此api转换到hsv色彩空间 - calcHist//接受单通道图像计算直方图, 参数略微复杂 - normalize//归一化,常用 - compareHist//比较直方图,可以得到两张图片的相似程度,但是对光非常敏感 - backProject();//直方图反向投影 笔记 这里是几个关于直方图的总结, 这一堆实在是不太好懂, 并且映射和统计接触到了很多数学方面的东西,重要的是理解思路以及了解API, 这里的东西要是有不理解的都建议去看官方的教程文档
直方图均衡化 好像在人脸识别的项目总结里写过了, API并不难理解
HSV模型 HSV是一种比较直观的颜色模型，所以在许多图像编辑工具中应用比较广泛，这个模型中颜色的参数分别是：色调（H, Hue），饱和度（S,Saturation），明度（V, Value）
直方图比较 compareHist(); API比较方便,输入两个直方图,比较他们的相似程度
这两个直方图通常会是图像的HS直方图(虽然我现在还不太懂HS为什么可以变成一张直方图,到时候要用再看原理好了),用HS猜测是要降低算法对光线的敏感度?(实测好像对光线还是很敏感)
OpenCV提供了一共四种方法
相关性计算:{-1, 1} //1最强 卡方计算:{0, ∞} //0最强 十字交叉 巴氏距离计算:{0, 1} //0最强 其中比较推荐的是相关性计算和巴氏距离计算(不需要归一化了hhhhhhhhh)
数学公式不列出了(反正我又不会去看)
直方图反向投影 mixChannels(); backProject(); 直方图反向投影是一种基于色彩的对象识别技术,通过该方法可以定位图像中已知物体的位置,反应直方图在目标图像中的分布
主要思路是提取已知图像的Hue(色相)空间,做出直方图,再反向找到这些色相在目标图片中的分布,已知图像中越多的色相,在backProject中就会(看起来)更亮,利用这点加上一些二值化,就可以得到一张目标物体的掩膜,覆盖到目标图片上就可以得到完成的图像了,如下
源//读取TIM图标, 在桌面截图上找到他 // OpenCV_Template....</p></section><footer class=entry-footer><span title="2020-02-19 00:00:00 +0000 UTC">February 19, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记11-直方图均衡化-直方图比较-反向投影" href=https://dynais.github.io/posts/nt-oc-a11_%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96_%E6%AF%94%E8%BE%83_%E5%8F%8D%E5%90%91%E6%8A%95%E5%BD%B1/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记10-霍夫线和圆检测</h2></header><section class=entry-content><p>API /*霍夫线检测 输入图像要先Canny过 参数为 - 输入图像 - 输出向量数组,数据类型为Vec4i(就是两个点) - 默认1 - 默认CV_PI / 180, 转角步长 - 阈值(我设了100) - 最小线长 - 最大间隙, 小于这个值的两条线会连成一条, 对于断断续续的线效果好 */ void HoughLinesP( InputArray image, OutputArray lines, double rho, double theta, int threshold, double minLineLength = 0, double maxLineGap = 0 ); /*霍夫圆检测 参数从前往后分别是 - 输入图像矩阵(8bit的灰度图,这个API自带Canny边缘检测) - 输出向量数组,数据类型位Vec3f - HOUGH_GRADIENT - 图像缩放,默认1 - 圆心最小距离, 小于会认为是同心圆? - Canny检测的大阈值,小的=大的除二计算 - 点重叠n个以上判定为圆,越小检出越多圆 - 最小圆半径 - 最大圆半径 */ void HoughCircles( InputArray image, OutputArray circles, int method, double dp, double minDist, double param1 = 100, double param2 = 100, int minRadius = 0, int maxRadius = 0 ); 笔记 圆检测对噪声敏感, 需要先中值滤波 太难了,建议看下面的博客,线检测还好,圆检测真的看不懂 相关 源//检出NXP赛道上的几何图 // OpenCV_Template....</p></section><footer class=entry-footer><span title="2020-02-16 22:00:00 +0000 UTC">February 16, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记10-霍夫线和圆检测" href=https://dynais.github.io/posts/nt-oc-a10_%E9%9C%8D%E5%A4%AB%E7%BA%BF%E5%92%8C%E5%9C%86%E6%A3%80%E6%B5%8B/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记09-Canny边缘检测算法</h2></header><section class=entry-content><p>API Canny(); //Canny的API, 包含了4个步骤. 注意, 不包含高斯模糊部分 笔记 Canny边缘检测算法可以分为以下5个步骤：
使用高斯滤波器，以平滑图像，滤除噪声。(需要调用高斯模糊API)
计算图像中每个像素点的梯度强度和方向。
应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。
应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。
通过抑制孤立的弱边缘最终完成边缘检测。
非极大值抑制:
细化边缘, 但技术的实现细节并不是很懂, 大致思想是取邻域中的梯度极大值点来进行有效边缘的判断, 下面的文章讲的很详细, 可以看看.
关于几种边缘检测方法: Laplance, Canny 和 Sobel 都是边缘检测的方法, Canny是包含了Sobel算子的边缘检测, 所以可以说是Sobel的实际应用, Laplance的检测效果并不好, 但是有其他的用途, 总的来说Canny能应对大多数的场景
参考来源 《A Computational Approach to Edge Detection》
源//对NXP赛道进行下采样和边缘检测 // OpenCV_Template.cpp : 此文件包含 "main" 函数。程序执行将在此处开始并结束。 // #include &lt;iostream>#include &lt;string>#include&lt;opencv2\opencv....</p></section><footer class=entry-footer><span title="2020-02-16 20:00:00 +0000 UTC">February 16, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记09-Canny边缘检测算法" href=https://dynais.github.io/posts/nt-oc-a09_canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记08-Sobel算子</h2></header><section class=entry-content><p>相关API Sobel();//索贝尔算子 Scharr();//Sobel的加强 笔记 Sobel: 边缘检测算法及各自的优缺点
Sobel是离散的一阶微分算子,可以用来计算图像的梯度(一阶), 常用于得到图像的边缘特征, 除了Sobel之外还有其他的算子, Sobel的优势是速度比较快, 但是在准确度上有欠缺
使用加减来简化计算机的负担: sobel算子的原理与实现
乘除对计算机很费力, 对计算机应该采用近似计算, 在Sobel求边缘的合成阶段使用到了这种思想
整个流程:
高斯->转灰度->求梯度x与y->混合
源 无</p></section><footer class=entry-footer><span title="2020-02-15 20:48:00 +0000 UTC">February 15, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记08-Sobel算子" href=https://dynais.github.io/posts/nt-oc-a08_sobel%E7%AE%97%E5%AD%90/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记07-上下采样-高斯不同(DOG)</h2></header><section class=entry-content><p>相关函数 - pyrUp();//上采样 - pyrDown();//下采样 - subtract();//图像减法 - threshold()//二值化 - binarythreshold()//还是二值化 笔记 高斯金字塔: 涉及到上采样和下采样的概念 实现步骤是: 1.高斯模糊 2.删除当前层偶数行列
高斯不同(DOG): 同图像在不同参数下做高斯模糊然后结果相减, 最后记得归一化, 不然图很淡
上/下采样对比几个像素求平均合成的优势:
最大的好处就是变快了, 在人脸识别那个项目里我自己写了压缩算法,但是速度和这个相差了一倍(在720p下)
但是也发现这个算法有局限, 首先图像会便模糊, 其次只能实现2的次方倍的缩放(至少根据OpenCV里的API来看)
源 无</p></section><footer class=entry-footer><span title="2020-02-15 20:39:00 +0000 UTC">February 15, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记07-上下采样-高斯不同(DOG)" href=https://dynais.github.io/posts/nt-oc-a07_%E4%B8%8A%E4%B8%8B%E9%87%87%E6%A0%B7_%E9%AB%98%E6%96%AF%E4%B8%8D%E5%90%8Cdog/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记06-形态学操作</h2></header><section class=entry-content><p>相关函数 getStructuringElement(int shape, Size ksize ,Point anchor);注意size还是要奇数 dilate(src, dst, kernel);膨胀 erode(src, dst, kernel);腐蚀 creatTrackbar();创建滑块,比较实用,但我搞不懂 morphologyEX();形态学操作 adaptiveThreshold(); threshold(); //大津法 实现 膨胀
腐蚀
开操作
形态学梯度
提取垂直或水平的线(使用水平或竖直的结构体)
二值化
对图像取反(用~)
笔记 opencv结构元素获取(getStructuringElement)我理解是类似卷积核的东西
膨胀:区域最大值覆盖中心值
腐蚀:区域最小值覆盖中心值
开操作:先腐蚀后膨胀,去掉小的对象
闭操作:先膨胀后腐蚀,填充小的洞
形态学梯度可以方便得提取边线
提取垂直或水平的线思路: 使用特殊的结构体来提取特殊的结构,比如一条横线进行开操作就可以提取出横线结构(操作完以后可以blur一下)
在进行阙值分割前对图像进行模糊处理(图像处理领域好像叫滤波?)再分割貌似有更好的效果...</p></section><footer class=entry-footer><span title="2020-01-30 00:00:00 +0000 UTC">January 30, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记06-形态学操作" href=https://dynais.github.io/posts/nt-oc-a06_%E5%BD%A2%E6%80%81%E5%AD%A6%E6%93%8D%E4%BD%9C/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记05-各类模糊</h2></header><section class=entry-content><p>相关函数 blur(); //均值模糊 GaussianBlur(); //高斯模糊 medianBlur(); //中值滤波 bilateralFilter() //双边滤波 实现 模糊
均值滤波 高斯滤波 中值滤波 双边滤波 笔记 高斯滤波是通过高斯函数也就是正态分布来给mask权重 sigma越大正态分布上表现就是越平滑 中值滤波是统计排序滤波器,对椒盐噪声有很好的抑制作用
注意区分中值和均值
高斯模糊没有考虑像素值的差异,会导致边缘还是不那么清晰
引入空间域核与值域核考虑,空间域就相当于普通的高斯滤波,根据相邻距离决定权重,而值域核是由目标像素值与中心像素值差来给定权重
简单来说就是双边模糊对高斯模糊来说多了一层mask,这层mask不是根据像素空间位置来给定权重的,而是根据像素与中心像素值之差得出
双边滤波可以磨皮(
剩下的看注释
相关 无
源 // OpenCV_Template.cpp : 此文件包含 "main" 函数。程序执行将在此处开始并结束。 // #include &lt;iostream>#include &lt;string>#include&lt;opencv2\opencv.hpp> using namespace std; using namespace cv; int main(int argc, char** argv){ /**************************************** 初始化 ****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread("Test....</p></section><footer class=entry-footer><span title="2020-01-29 00:00:00 +0000 UTC">January 29, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记05-各类模糊" href=https://dynais.github.io/posts/nt-oc-a05_%E5%90%84%E7%B1%BB%E6%A8%A1%E7%B3%8A/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>OpenCV学习笔记04-图像混合-亮度对比度-几何绘制</h2></header><section class=entry-content><p>相关函数 mat.at&lt;xxx> bitwise_not();//反色 src.convertTo();//通道转换 addWeighted()//图像混合加权相加,大小类型必须一致 multiply()//图像相乘 Mat::zeros cv:point cv:scalar line(); cv:rect rectangle(); 实现 对像素的操作 图像混合 对比度和亮度调节 几何绘制(人脸追踪框可能) 笔记 通过权重相加函数实现图像混合效果 addWeighted() 对比度和亮度调节的实现思想 像素值相乘(对比度实现,因为拉大了数值差) 像素值加常数(亮度实现) 公式:g(x,y) = alpha * f(x,y) + beta 相关 无
源 // OpenCV_Template.cpp : 此文件包含 "main" 函数。程序执行将在此处开始并结束。 // #include &lt;iostream>#include &lt;string>#include&lt;opencv2\opencv.hpp> using namespace std; using namespace cv; int main(int argc, char** argv){ /**************************************** 初始化 ****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread("Test....</p></section><footer class=entry-footer><span title="2020-01-25 00:00:00 +0000 UTC">January 25, 2020</span></footer><a class=entry-link aria-label="post link to OpenCV学习笔记04-图像混合-亮度对比度-几何绘制" href=https://dynais.github.io/posts/nt-oc-a04_%E5%9B%BE%E5%83%8F%E6%B7%B7%E5%90%88_%E4%BA%AE%E5%BA%A6%E5%AF%B9%E6%AF%94%E5%BA%A6_%E5%87%A0%E4%BD%95%E7%BB%98%E5%88%B6/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://dynais.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://dynais.github.io/>DynAis</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>