[{"content":"在某一个虚拟环境中完成脚本后, 想要实际使用时可能会出现错误 这是由于虚拟环境和运行环境不一致导致依赖库缺失无法import导致的\n 问题描述 在某一个虚拟环境中完成脚本后, 想要实际使用时可能会出现错误 这是由于虚拟环境和运行环境不一致导致依赖库缺失无法import导致的\n解决方法 解决方式就是在编写脚本时, 对于第三方的库进行一次检测, 如果没有的话就进行pip install\ntry: import regex as re except ImportError: os.system(\u0026#39;pip install regex\u0026#39;) import regex as re 对于小脚本来说这样就足够了, 项目大的话不建议这样使用\n","permalink":"https://dynais.github.io/code/posts/code.python.%E8%A7%A3%E5%86%B3python%E8%84%9A%E6%9C%AC%E5%9C%A8%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E4%B8%8B%E4%BE%9D%E8%B5%96%E5%BA%93%E7%BC%BA%E5%A4%B1%E7%9A%84%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e在某一个虚拟环境中完成脚本后, 想要实际使用时可能会出现错误\n\u003cimg loading=\"lazy\" src=\"https://dynais-imh-hub.oss-cn-hangzhou.aliyuncs.com/img/20210223124433.png?x-oss-process=image/resize,h_2000/quality,q_90#center\" alt=\"\"  /\u003e\n\n这是由于虚拟环境和运行环境不一致导致依赖库缺失无法\u003ccode\u003eimport\u003c/code\u003e导致的\u003c/p\u003e","title":"解决Python脚本在运行环境下依赖库缺失的问题"},{"content":"线性回归是回归问题中的一种，线性回归假设目标值与特征之间线性相关，即满足一个多元一次方程。\n 通过构建损失函数，来求解损失函数最小时的参数 $w$ 和$b$。通常我们可以表达成如下公式： $$ \\hat{y} = wX + b $$ $\\hat{y}$ 为预测值，自变量 $x$ 和因变量 $y$ 是已知的，而我们想实现的是预测新增一个 $x$ ，其对应的 $y$ 是多少。因此，为了构建这个函数关系，目标是通过已知数据点，求解线性模型中 $w$ 和 $b$ 两个参数。\n1.线性回归概述  线性回归是回归问题中的一种，线性回归假设目标值与特征之间线性相关，即满足一个多元一次方程。通过构建损失函数，来求解损失函数最小时的参数 $w$ 和$b$。通常我们可以表达成如下公式：\n$$ \\hat{y} = wX + b \\tag{1} $$\n$\\hat{y}$ 为预测值，自变量 $x$ 和因变量 $y$ 是已知的，而我们想实现的是预测新增一个 $x$ ，其对应的 $y$ 是多少。因此，为了构建这个函数关系，目标是通过已知数据点，求解线性模型中 $w$ 和 $b$ 两个参数。\n为此, 线性回归分为两个部分, 向前传播和向后传播, 向前传播负责验证当前参数下对数据的拟合程度, 而向后传播通过在向前传播内得到的数据对参数进行优化\n2.向前传播 2.1.进行数据预处理 拟合数据之前, 需要对数据先进行预处理\n参数初始化 参数 $w$ 和 $b$ 对初始化没有特别的需求, 置 $0$ 即可\n特征缩放/均一化 对于输入特征值矩阵 $X$ 中数据规模差距大的时候, 应该事先对数据进行特征缩放, 此举的目的是为了在计算中使梯度更快的收敛\n2.2.计算预测结果及损失函数 求解最佳参数，需要一个标准来对结果进行衡量，为此我们需要定量化一个目标函数式，使得计算机可以在求解过程中不断地优化。\n针对任何模型求解问题，都是最终都是可以得到一组预测值 $\\hat{y}$ ，对比已有的真实值 $y$ ，数据行数为 $m$ ，可以将损失函数定义如下： $$ J = \\frac{1}{m}\\sum_{i=1}^{m}{(\\hat{y_i} - y_i)^2} \\tag{2} $$ 值 $J$ 就代表着当前模型和数据点的偏移程度\n3.向后传播 3.1.梯度下降 计算出损失函数之后, 通过使用原有参数减去一个常数与函数求导结果相乘的方式就可以不断地减小损失函数的值, 使参数不断收敛到最佳值, 这种方法在数学上也被称为最小二乘法, 在这里我们称为梯度下降:\n$$ w := w - \\alpha \\cdot dw \\tag{3} $$ $$ d := d - \\alpha \\cdot dw \\tag{4} $$\n3.2.学习速率α 梯度下降算法的每次迭代受到学习率影响, 如果 $\\alpha$ 过小, 则达到收敛所需的迭代次数会非常高; 如果学习率 $\\alpha$ 过大,每次迭代可能不会减小价函数, 可能越局部最大, 导致无法收敛\n使用时可以从小到大成倍增加尝试, 如 $0.01, 0.02, 0.04 \u0026hellip;$\n4.拓展-多项式回归 有时候, 预测结果与输入值之间的关系并非是线性的, 此时就需要使用多项式回归进行拟合\n比如一个二次方模型: $$ \\hat{y} = w_1 x_1 + w_2 x_2^2 + d \\tag{5} $$ 此时可以使 $$ x_2 = x^2 \\tag{6} $$ 来转化问题成为一个线性回归问题\n5.拓展-正规方程  通过正规方程可以直接解出向量 $w$, 这种方法适用于样本量不大的情况 $$ w = (X^T X)^{-1} X^T Y \\tag{7} $$\n参考  机器学习 | 算法笔记- 线性回归（Linear Regression） ","permalink":"https://dynais.github.io/code/posts/code.ml.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/","summary":"\u003cp\u003e线性回归是回归问题中的一种，线性回归假设目标值与特征之间线性相关，即满足一个多元一次方程。\u003c/p\u003e","title":"线性回归模型"},{"content":"关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.\n而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:\n 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:\n 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:\n 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:\nhttps://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/\nhttps://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb\n  前言:\n为什么要删去数据集中重复的图片?\nHaving duplicate images in your dataset creates a problem for two reasons:\n It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize.\n 一. 关于图像散列值 关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.\n而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:\n 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:\n 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:\n 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  二. 我们所需的步骤 1. Convert to grayscale 转灰度 在这里, 颜色信息对于判定两张图是否相同其实并不是很重要, 所以将三通道转为一个通道可以很好的减少我们的工作量\n2. Resize 忽略长宽比缩放 这是为了得到一个合适的大小, 以便符合后续的Hash计算, 所有需要保证所有的图片具有相同的大小尺寸, 这牵扯到差分散列的工作原理, 这会在后面解释\n在这里, 我们需要将原图缩放到只有$ 9 * 8 $大小\n3. Compute the difference 计算差分(梯度) 差分散列算法, 故名思与需要计算差分信息, 在图片里, 指的就是相邻像素之间的梯度.\n好了, 这就是之前我们为什么需要 $ 9 * 8 $ 像素的原因了\n因为我们需要得到的是一个64位的二进制信息, 而 $8 * 8=64$ , 由于是计算差分(梯度), 所以必然需要九行\n需要注意: 这里虽然说是差分, 但实际上使用的是非常简化的版本: 但前一个像素大于后一个像素时, 给出一个$1$, 否则, 给出一个$0$, 也就是说, 可以看作只提取梯度的正负符号信息, 公式为\n​\t$P[x] \u0026gt; P[x + 1] = 1 else 0$\n那么现在我们得到了一个64bit的值, 接下来就对他进行Hash计算\n4. Build the hash 计算散列值 def dhash(image, hashSize=8): # convert the image to grayscale and resize the grayscale image, # adding a single column (width) so we can compute the horizontal # gradient gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) resized = cv2.resize(gray, (hashSize + 1, hashSize)) # compute the (relative) horizontal gradient between adjacent # column pixels diff = resized[:, 1:] \u0026gt; resized[:, :-1] # convert the difference image to a hash and return it return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v]) 5. 初始化字典, 寻找重复并输出 略\n","permalink":"https://dynais.github.io/code/posts/code.cv.%E4%BD%BF%E7%94%A8%E5%B7%AE%E5%88%86%E6%95%A3%E5%88%97%E6%A3%80%E6%B5%8B%E9%87%8D%E5%A4%8D%E5%9B%BE%E7%89%87/","summary":"关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.\n而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:\n 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:\n 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:\n 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:\nhttps://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/\nhttps://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb\n  前言:\n为什么要删去数据集中重复的图片?\nHaving duplicate images in your dataset creates a problem for two reasons:\n It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize.","title":"使用差分散列检测重复图片"},{"content":"API matchTemplate();//模式查找,API比较简单 minMaxLoc();//用于在模式查找的输出图像中找到极值点,也就是匹配点 笔记   模板匹配(Templet Match)\n相当于上一节说的直方图匹配的实用化,通过现有图像在目标图像上滑行(原文Slide),也就是左到右上到下的以像素为单位进行匹配,找到匹配值最大的点.但也是因为这个原因,对模板图像和在目标图像里的目标的大小进行匹配就非常重要,如果大小差得远,效果就不好,所以使用条件相当苛刻.\n  注意输出图像的大小\n在API中需要提供一个储存输出结果的Mat, 他的大小是\nSize(src.cols-templ.cols+1, src.rows-templ.rows+1)     OpenCV的查找模式\nOpenCV提供了很多种方法,在官网上都有介绍,大部分都是取用了最大值作为最匹配\n根据最小值匹配的只有 TM_SQDIFF 和 MT_SQDIFF_NORMED\nFor the first two methods ( TM_SQDIFF and MT_SQDIFF_NORMED ) the best match are the lowest values.\n  OpenCV中32位的图像\n每个数值是一个位于[0,1]间的小数,相当于8位的[0,255]\n   源//API实现模式查找 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; Mat src, dst, temp; int main(int, char**) { temp = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV Learning/ImageHub/Lena.jpg\u0026#34;); src = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV Learning/ImageHub/Day1.png\u0026#34;); //测试尺度不变性 \t//pyrDown(temp, temp, Size(temp.cols / 2, temp.rows / 2)); \tpyrUp(temp, temp, Size(temp.cols * 2, temp.rows * 2)); //pyrUp(temp, temp, Size(temp.cols * 2, temp.rows * 2));  if (temp.empty() || src.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG... Check again!\u0026#34;; return -1; } Mat result = Mat_\u0026lt;float\u0026gt;::zeros(src.cols - temp.cols + 1, src.rows - temp.rows + 1 ); matchTemplate(src, temp, result, TM_CCOEFF_NORMED); //cout \u0026lt;\u0026lt; result;  double minVal; double maxVal; Point minLoc; Point maxLoc; Point matchLoc; minMaxLoc(result, \u0026amp;minVal, \u0026amp;maxVal, \u0026amp;minLoc, \u0026amp;maxLoc, Mat()); cout \u0026lt;\u0026lt; minVal \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; maxVal \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; minLoc \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; maxLoc \u0026lt;\u0026lt; endl; rectangle(src, maxLoc, Point(maxLoc.x + temp.cols, maxLoc.y + temp.rows), Scalar(0,0,255), 2, 8); rectangle(result, Point(maxLoc.x - temp.cols/2, maxLoc.y - temp.rows/2), Point(maxLoc.x + temp.cols/2, maxLoc.y + temp.rows/2), Scalar::all(1), 2, 8, 0); namedWindow(\u0026#34;src\u0026#34;, WINDOW_AUTOSIZE); pyrDown(src, src, Size(src.cols / 2, src.rows / 2)); pyrDown(src, src, Size(src.cols / 2, src.rows / 2)); imshow(\u0026#34;src\u0026#34;, src); namedWindow(\u0026#34;result\u0026#34;, WINDOW_AUTOSIZE); pyrDown(result, result, Size(result.cols / 2, result.rows / 2)); pyrDown(result, result, Size(result.cols / 2, result.rows / 2)); imshow(\u0026#34;result\u0026#34;, result); waitKey(0); return 0; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E6%A8%A1%E6%9D%BF%E5%8C%B9%E9%85%8D/","summary":"API matchTemplate();//模式查找,API比较简单 minMaxLoc();//用于在模式查找的输出图像中找到极值点,也就是匹配点 笔记   模板匹配(Templet Match)\n相当于上一节说的直方图匹配的实用化,通过现有图像在目标图像上滑行(原文Slide),也就是左到右上到下的以像素为单位进行匹配,找到匹配值最大的点.但也是因为这个原因,对模板图像和在目标图像里的目标的大小进行匹配就非常重要,如果大小差得远,效果就不好,所以使用条件相当苛刻.\n  注意输出图像的大小\n在API中需要提供一个储存输出结果的Mat, 他的大小是\nSize(src.cols-templ.cols+1, src.rows-templ.rows+1)     OpenCV的查找模式\nOpenCV提供了很多种方法,在官网上都有介绍,大部分都是取用了最大值作为最匹配\n根据最小值匹配的只有 TM_SQDIFF 和 MT_SQDIFF_NORMED\nFor the first two methods ( TM_SQDIFF and MT_SQDIFF_NORMED ) the best match are the lowest values.\n  OpenCV中32位的图像\n每个数值是一个位于[0,1]间的小数,相当于8位的[0,255]\n   源//API实现模式查找 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; Mat src, dst, temp; int main(int, char**) { temp = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV Learning/ImageHub/Lena.","title":"[CV] 模版匹配"},{"content":"API - equalizeHist();//直方图均衡化 - split();//分离通道 - calcHist();//参数dims,bin,range - waitkey(); - mixChannels//分离通道, 与split小有差别,建议看官方文档 - cvtColer//使用此api转换到hsv色彩空间 - calcHist//接受单通道图像计算直方图, 参数略微复杂 - normalize//归一化,常用 - compareHist//比较直方图,可以得到两张图片的相似程度,但是对光非常敏感 - backProject();//直方图反向投影 笔记 这里是几个关于直方图的总结, 这一堆实在是不太好懂, 并且映射和统计接触到了很多数学方面的东西,重要的是理解思路以及了解API, 这里的东西要是有不理解的都建议去看官方的教程文档\n 直方图均衡化  好像在人脸识别的项目总结里写过了, API并不难理解\n HSV模型  HSV是一种比较直观的颜色模型，所以在许多图像编辑工具中应用比较广泛，这个模型中颜色的参数分别是：色调（H, Hue），饱和度（S,Saturation），明度（V, Value）\n 直方图比较  compareHist(); API比较方便,输入两个直方图,比较他们的相似程度\n这两个直方图通常会是图像的HS直方图(虽然我现在还不太懂HS为什么可以变成一张直方图,到时候要用再看原理好了),用HS猜测是要降低算法对光线的敏感度?(实测好像对光线还是很敏感)\nOpenCV提供了一共四种方法\n 相关性计算:{-1, 1} //1最强 卡方计算:{0, ∞} //0最强 十字交叉 巴氏距离计算:{0, 1} //0最强  其中比较推荐的是相关性计算和巴氏距离计算(不需要归一化了hhhhhhhhh)\n数学公式不列出了(反正我又不会去看)\n 直方图反向投影  mixChannels(); backProject(); 直方图反向投影是一种基于色彩的对象识别技术,通过该方法可以定位图像中已知物体的位置,反应直方图在目标图像中的分布\n主要思路是提取已知图像的Hue(色相)空间,做出直方图,再反向找到这些色相在目标图片中的分布,已知图像中越多的色相,在backProject中就会(看起来)更亮,利用这点加上一些二值化,就可以得到一张目标物体的掩膜,覆盖到目标图片上就可以得到完成的图像了,如下\n 源//读取TIM图标, 在桌面截图上找到他 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026#34;opencv2/imgproc.hpp\u0026#34;#include \u0026#34;opencv2/imgcodecs.hpp\u0026#34;#include \u0026#34;opencv2/highgui.hpp\u0026#34;#include \u0026lt;iostream\u0026gt; using namespace cv; using namespace std; Mat hue; Mat target_hue; int bins = 25; Mat src_mask_globle; Mat target; void Hist_and_Backproj(int, void*); int main(int argc, char* argv[]) { //读入src  CommandLineParser parser(argc, argv, \u0026#34;{@input |D:/WorkSpace/Projects/OpenCV Learning/ImageHub/Tim.png | input image}\u0026#34;); Mat src = imread(parser.get\u0026lt;String\u0026gt;(\u0026#34;@input\u0026#34;)); if (src.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Could not open or find the image!\\n\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;Usage: \u0026#34; \u0026lt;\u0026lt; argv[0] \u0026lt;\u0026lt; \u0026#34; \u0026lt;Input image\u0026gt;\u0026#34; \u0026lt;\u0026lt; endl; return -1; } target = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV Learning/ImageHub/屏幕.png\u0026#34;); pyrDown(target, target, Size(target.cols / 2, target.rows / 2)); pyrDown(target, target, Size(target.cols / 2, target.rows / 2)); //pyrDown(src, src, Size(src.cols / 2, src.rows / 2));  //二值化取覆膜  Mat src_gray; cvtColor(src, src_gray, COLOR_BGR2GRAY); Mat src_mask; threshold(src_gray, src_mask, 0, 255, THRESH_TRIANGLE); src_mask_globle = src_mask; imshow(\u0026#34;BinMask\u0026#34;, src_mask); //色彩空间转换  //src = Mat(src.size(), src.type(), Scalar(255, 0, 0));  Mat hsv; cvtColor(src, hsv, COLOR_BGR2HSV); Mat target_hsv; cvtColor(target, target_hsv, COLOR_BGR2HSV); //创建Hue空间通道图像  hue.create(hsv.size(), hsv.depth()); target_hue.create(target_hsv.size(), target_hsv.depth()); int ch[] = { 0, 0 }; mixChannels(\u0026amp;hsv, 1, \u0026amp;hue, 1, ch, 1); mixChannels(\u0026amp;target_hsv, 1, \u0026amp;target_hue, 1, ch, 1); //cout \u0026lt;\u0026lt; hue;  //创建滑块并BackProjection  const char* window_image = \u0026#34;Source image\u0026#34;; namedWindow(window_image); createTrackbar(\u0026#34;* Hue bins: \u0026#34;, window_image, \u0026amp;bins, 180, Hist_and_Backproj); Hist_and_Backproj(0, 0); imshow(window_image, src); // Wait until user exits the program  waitKey(0); return 0; } void Hist_and_Backproj(int, void*) { //防止bins太小  int histSize = MAX(bins, 2); //计算Hue空间直方图  float hue_range[] = { 0, 180 }; const float* ranges = { hue_range }; Mat hist; calcHist(\u0026amp;hue, 1, 0, src_mask_globle, hist, 1, \u0026amp;histSize, \u0026amp;ranges, true, false); normalize(hist, hist, 0, 255, NORM_MINMAX, -1, Mat()); //BackProjection  Mat backproj; calcBackProject(\u0026amp;target_hue, 1, 0, hist, backproj, \u0026amp;ranges, 1, true); threshold(backproj, backproj, 0, 255, THRESH_OTSU); imshow(\u0026#34;BackProj\u0026#34;, backproj); //绘制直方图  int w = 400, h = 400; int bin_w = cvRound((double)w / histSize); Mat histImg = Mat::zeros(h, w, CV_8UC3); for (int i = 0; i \u0026lt; bins; i++) { rectangle(histImg, Point(i * bin_w, h), Point((i + 1) * bin_w, h - cvRound(hist.at\u0026lt;float\u0026gt;(i) * h / 255.0)), Scalar(0, 0, 255), FILLED); } imshow(\u0026#34;Histogram\u0026#34;, histImg); Mat focus; target.copyTo(focus, backproj); imshow(\u0026#34;focus\u0026#34;, focus); } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96_%E6%AF%94%E8%BE%83_%E5%8F%8D%E5%90%91%E6%8A%95%E5%BD%B1/","summary":"API - equalizeHist();//直方图均衡化 - split();//分离通道 - calcHist();//参数dims,bin,range - waitkey(); - mixChannels//分离通道, 与split小有差别,建议看官方文档 - cvtColer//使用此api转换到hsv色彩空间 - calcHist//接受单通道图像计算直方图, 参数略微复杂 - normalize//归一化,常用 - compareHist//比较直方图,可以得到两张图片的相似程度,但是对光非常敏感 - backProject();//直方图反向投影 笔记 这里是几个关于直方图的总结, 这一堆实在是不太好懂, 并且映射和统计接触到了很多数学方面的东西,重要的是理解思路以及了解API, 这里的东西要是有不理解的都建议去看官方的教程文档\n 直方图均衡化  好像在人脸识别的项目总结里写过了, API并不难理解\n HSV模型  HSV是一种比较直观的颜色模型，所以在许多图像编辑工具中应用比较广泛，这个模型中颜色的参数分别是：色调（H, Hue），饱和度（S,Saturation），明度（V, Value）\n 直方图比较  compareHist(); API比较方便,输入两个直方图,比较他们的相似程度\n这两个直方图通常会是图像的HS直方图(虽然我现在还不太懂HS为什么可以变成一张直方图,到时候要用再看原理好了),用HS猜测是要降低算法对光线的敏感度?(实测好像对光线还是很敏感)\nOpenCV提供了一共四种方法\n 相关性计算:{-1, 1} //1最强 卡方计算:{0, ∞} //0最强 十字交叉 巴氏距离计算:{0, 1} //0最强  其中比较推荐的是相关性计算和巴氏距离计算(不需要归一化了hhhhhhhhh)\n数学公式不列出了(反正我又不会去看)\n 直方图反向投影  mixChannels(); backProject(); 直方图反向投影是一种基于色彩的对象识别技术,通过该方法可以定位图像中已知物体的位置,反应直方图在目标图像中的分布\n主要思路是提取已知图像的Hue(色相)空间,做出直方图,再反向找到这些色相在目标图片中的分布,已知图像中越多的色相,在backProject中就会(看起来)更亮,利用这点加上一些二值化,就可以得到一张目标物体的掩膜,覆盖到目标图片上就可以得到完成的图像了,如下\n 源//读取TIM图标, 在桌面截图上找到他 // OpenCV_Template.","title":"[CV] 直方图均衡化-直方图比较-反向投影"},{"content":"API Canny();\t//Canny的API, 包含了4个步骤. 注意, 不包含高斯模糊部分 笔记   Canny边缘检测算法可以分为以下5个步骤：\n  使用高斯滤波器，以平滑图像，滤除噪声。(需要调用高斯模糊API)\n  计算图像中每个像素点的梯度强度和方向。\n  应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。\n  应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。\n  通过抑制孤立的弱边缘最终完成边缘检测。\n    非极大值抑制:\n  细化边缘, 但技术的实现细节并不是很懂, 大致思想是取邻域中的梯度极大值点来进行有效边缘的判断, 下面的文章讲的很详细, 可以看看.\n 关于几种边缘检测方法:  Laplance, Canny 和 Sobel 都是边缘检测的方法, Canny是包含了Sobel算子的边缘检测, 所以可以说是Sobel的实际应用, Laplance的检测效果并不好, 但是有其他的用途, 总的来说Canny能应对大多数的场景\n参考来源   《A Computational Approach to Edge Detection》\n   源//对NXP赛道进行下采样和边缘检测 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; Mat imgIn, imgOut; int main(int argc, char** argv) { /****************************************\t初始化\t****************************************************/ imgIn = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV Learning/ImageHub/直道进圆环.jpg\u0026#34;, IMREAD_COLOR); if (imgIn.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG...\u0026#34; \u0026lt;\u0026lt; endl; return -1; } //VideoCapture(0) \u0026gt;\u0026gt; imgIn; \timgOut = imgIn.clone(); /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ double tCount = 0; double tSum = 0; tCount = getTickCount(); cvtColor(imgIn, imgOut, COLOR_BGR2GRAY);//Canny只接受8位深度的灰度图 \tpyrDown(imgOut, imgOut, Size(imgOut.cols / 2, imgOut.rows / 2));//下采样 \tpyrDown(imgOut, imgOut, Size(imgOut.cols / 2, imgOut.rows / 2)); pyrDown(imgOut, imgOut, Size(imgOut.cols / 2, imgOut.rows / 2)); //GaussianBlur(imgOut, imgOut, Size(3, 3), 1.4);  Canny(imgOut, imgOut, 50, 125, 3);//第三,四个参数代表上下阈值, 第五个是Sobel算子的大小, 一般取3  tSum = (getTickCount() - tCount) / getTickFrequency(); printf(\u0026#34;Time consume %.4f\\n\\n\u0026#34;, tSum); /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ namedWindow(\u0026#34;input\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;input\u0026#34;, imgIn); namedWindow(\u0026#34;output\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output\u0026#34;, imgOut); waitKey(0); //cout \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl; } /****************************************\t图像输出\t****************************************************/ // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/","summary":"API Canny();\t//Canny的API, 包含了4个步骤. 注意, 不包含高斯模糊部分 笔记   Canny边缘检测算法可以分为以下5个步骤：\n  使用高斯滤波器，以平滑图像，滤除噪声。(需要调用高斯模糊API)\n  计算图像中每个像素点的梯度强度和方向。\n  应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。\n  应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。\n  通过抑制孤立的弱边缘最终完成边缘检测。\n    非极大值抑制:\n  细化边缘, 但技术的实现细节并不是很懂, 大致思想是取邻域中的梯度极大值点来进行有效边缘的判断, 下面的文章讲的很详细, 可以看看.\n 关于几种边缘检测方法:  Laplance, Canny 和 Sobel 都是边缘检测的方法, Canny是包含了Sobel算子的边缘检测, 所以可以说是Sobel的实际应用, Laplance的检测效果并不好, 但是有其他的用途, 总的来说Canny能应对大多数的场景\n参考来源   《A Computational Approach to Edge Detection》\n   源//对NXP赛道进行下采样和边缘检测 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.","title":"[CV] Canny边缘检测算法"},{"content":"API /*霍夫线检测 输入图像要先Canny过 参数为 - 输入图像 - 输出向量数组,数据类型为Vec4i(就是两个点) - 默认1 - 默认CV_PI / 180, 转角步长 - 阈值(我设了100) - 最小线长 - 最大间隙, 小于这个值的两条线会连成一条, 对于断断续续的线效果好 */ void HoughLinesP( InputArray image, OutputArray lines, double rho, double theta, int threshold, double minLineLength = 0, double maxLineGap = 0 ); /*霍夫圆检测 参数从前往后分别是 - 输入图像矩阵(8bit的灰度图,这个API自带Canny边缘检测) - 输出向量数组,数据类型位Vec3f - HOUGH_GRADIENT - 图像缩放,默认1 - 圆心最小距离, 小于会认为是同心圆? - Canny检测的大阈值,小的=大的除二计算 - 点重叠n个以上判定为圆,越小检出越多圆 - 最小圆半径 - 最大圆半径 */ void HoughCircles( InputArray image, OutputArray circles, int method, double dp, double minDist, double param1 = 100, double param2 = 100, int minRadius = 0, int maxRadius = 0 ); 笔记  圆检测对噪声敏感, 需要先中值滤波 太难了,建议看下面的博客,线检测还好,圆检测真的看不懂  相关 源//检出NXP赛道上的几何图 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; Mat imgIn, imgOut; int main(int argc, char** argv) { /****************************************\t初始化\t****************************************************/ imgIn = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV Learning/ImageHub/直道进圆环.jpg\u0026#34;, IMREAD_COLOR); if (imgIn.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG...\u0026#34; \u0026lt;\u0026lt; endl; return -1; } //VideoCapture(0) \u0026gt;\u0026gt; imgIn; \timgOut = imgIn.clone(); /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ double tCount = 0; double tSum = 0; tCount = getTickCount(); cvtColor(imgIn, imgIn, COLOR_BGR2GRAY); pyrDown(imgIn, imgIn, Size(imgIn.cols / 2, imgIn.rows / 2)); pyrDown(imgIn, imgIn, Size(imgIn.cols / 2, imgIn.rows / 2)); pyrDown(imgIn, imgIn, Size(imgIn.cols / 2, imgIn.rows / 2)); //GaussianBlur(imgOut, imgOut, Size(3, 3), 1.4);  //霍夫圆检测 \timgOut = Mat::zeros(imgIn.size(), imgIn.type()); vector\u0026lt;Vec3f\u0026gt; circles; HoughCircles(imgIn, circles, HOUGH_GRADIENT, 1, 50, 125, 30);//参数很难试 \tVec3f aCircle; for (size_t i = 0; i \u0026lt; circles.size(); i++) { aCircle = circles[i]; circle(imgOut, Point(aCircle[0],aCircle[1]), aCircle[2], Scalar(255), 1, LINE_AA); } //霍夫直线检测 \tvector\u0026lt;Vec4i\u0026gt; lines; Canny(imgIn, imgIn, 50, 125, 3); HoughLinesP(imgIn, lines, 1, CV_PI / 180, 60, 0.0, 20.0); Vec4i aLine; for (size_t i = 0; i \u0026lt; lines.size(); i++) { aLine = lines[i]; line(imgOut, Point(aLine[0], aLine[1]), Point(aLine[2], aLine[3]) ,Scalar(255), 1, LINE_AA); } tSum = (getTickCount() - tCount) / getTickFrequency(); printf(\u0026#34;Time consume %.4f\\n\\n\u0026#34;, tSum); /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ namedWindow(\u0026#34;input\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;input\u0026#34;, imgIn); namedWindow(\u0026#34;output\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output\u0026#34;, imgOut); waitKey(0); //cout \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl; } /****************************************\t图像输出\t****************************************************/ // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E9%9C%8D%E5%A4%AB%E7%BA%BF%E5%92%8C%E5%9C%86%E6%A3%80%E6%B5%8B/","summary":"API /*霍夫线检测 输入图像要先Canny过 参数为 - 输入图像 - 输出向量数组,数据类型为Vec4i(就是两个点) - 默认1 - 默认CV_PI / 180, 转角步长 - 阈值(我设了100) - 最小线长 - 最大间隙, 小于这个值的两条线会连成一条, 对于断断续续的线效果好 */ void HoughLinesP( InputArray image, OutputArray lines, double rho, double theta, int threshold, double minLineLength = 0, double maxLineGap = 0 ); /*霍夫圆检测 参数从前往后分别是 - 输入图像矩阵(8bit的灰度图,这个API自带Canny边缘检测) - 输出向量数组,数据类型位Vec3f - HOUGH_GRADIENT - 图像缩放,默认1 - 圆心最小距离, 小于会认为是同心圆? - Canny检测的大阈值,小的=大的除二计算 - 点重叠n个以上判定为圆,越小检出越多圆 - 最小圆半径 - 最大圆半径 */ void HoughCircles( InputArray image, OutputArray circles, int method, double dp, double minDist, double param1 = 100, double param2 = 100, int minRadius = 0, int maxRadius = 0 ); 笔记  圆检测对噪声敏感, 需要先中值滤波 太难了,建议看下面的博客,线检测还好,圆检测真的看不懂  相关 源//检出NXP赛道上的几何图 // OpenCV_Template.","title":"[CV] 霍夫线和圆检测"},{"content":"相关API Sobel();//索贝尔算子 Scharr();//Sobel的加强 笔记   Sobel: 边缘检测算法及各自的优缺点\nSobel是离散的一阶微分算子,可以用来计算图像的梯度(一阶), 常用于得到图像的边缘特征, 除了Sobel之外还有其他的算子, Sobel的优势是速度比较快, 但是在准确度上有欠缺\n  使用加减来简化计算机的负担: sobel算子的原理与实现\n乘除对计算机很费力, 对计算机应该采用近似计算, 在Sobel求边缘的合成阶段使用到了这种思想\n  整个流程:\n高斯-\u0026gt;转灰度-\u0026gt;求梯度x与y-\u0026gt;混合\n  源 无 ","permalink":"https://dynais.github.io/code/posts/code.cv.sobel%E7%AE%97%E5%AD%90/","summary":"相关API Sobel();//索贝尔算子 Scharr();//Sobel的加强 笔记   Sobel: 边缘检测算法及各自的优缺点\nSobel是离散的一阶微分算子,可以用来计算图像的梯度(一阶), 常用于得到图像的边缘特征, 除了Sobel之外还有其他的算子, Sobel的优势是速度比较快, 但是在准确度上有欠缺\n  使用加减来简化计算机的负担: sobel算子的原理与实现\n乘除对计算机很费力, 对计算机应该采用近似计算, 在Sobel求边缘的合成阶段使用到了这种思想\n  整个流程:\n高斯-\u0026gt;转灰度-\u0026gt;求梯度x与y-\u0026gt;混合\n  源 无 ","title":"[CV] Sobel算子"},{"content":"相关函数 - pyrUp();//上采样 - pyrDown();//下采样 - subtract();//图像减法  - threshold()//二值化 - binarythreshold()//还是二值化 笔记   高斯金字塔: 涉及到上采样和下采样的概念 实现步骤是: 1.高斯模糊 2.删除当前层偶数行列\n  高斯不同(DOG): 同图像在不同参数下做高斯模糊然后结果相减, 最后记得归一化, 不然图很淡\n    上/下采样对比几个像素求平均合成的优势:\n最大的好处就是变快了, 在人脸识别那个项目里我自己写了压缩算法,但是速度和这个相差了一倍(在720p下)\n但是也发现这个算法有局限, 首先图像会便模糊, 其次只能实现2的次方倍的缩放(至少根据OpenCV里的API来看)\n  源 无 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E4%B8%8A%E4%B8%8B%E9%87%87%E6%A0%B7_%E9%AB%98%E6%96%AF%E4%B8%8D%E5%90%8Cdog/","summary":"相关函数 - pyrUp();//上采样 - pyrDown();//下采样 - subtract();//图像减法  - threshold()//二值化 - binarythreshold()//还是二值化 笔记   高斯金字塔: 涉及到上采样和下采样的概念 实现步骤是: 1.高斯模糊 2.删除当前层偶数行列\n  高斯不同(DOG): 同图像在不同参数下做高斯模糊然后结果相减, 最后记得归一化, 不然图很淡\n    上/下采样对比几个像素求平均合成的优势:\n最大的好处就是变快了, 在人脸识别那个项目里我自己写了压缩算法,但是速度和这个相差了一倍(在720p下)\n但是也发现这个算法有局限, 首先图像会便模糊, 其次只能实现2的次方倍的缩放(至少根据OpenCV里的API来看)\n  源 无 ","title":"[CV] 上下采样-高斯不同(DOG)"},{"content":"相关函数 getStructuringElement(int shape, Size ksize ,Point anchor);注意size还是要奇数 dilate(src, dst, kernel);膨胀 erode(src, dst, kernel);腐蚀 creatTrackbar();创建滑块,比较实用,但我搞不懂 morphologyEX();形态学操作 adaptiveThreshold(); threshold(); //大津法 实现   膨胀\n  腐蚀\n  开操作\n  形态学梯度\n  提取垂直或水平的线(使用水平或竖直的结构体)\n  二值化\n  对图像取反(用~)\n  笔记   opencv结构元素获取(getStructuringElement)我理解是类似卷积核的东西\n  膨胀:区域最大值覆盖中心值\n  腐蚀:区域最小值覆盖中心值\n  开操作:先腐蚀后膨胀,去掉小的对象\n  闭操作:先膨胀后腐蚀,填充小的洞\n  形态学梯度可以方便得提取边线\n  提取垂直或水平的线思路: 使用特殊的结构体来提取特殊的结构,比如一条横线进行开操作就可以提取出横线结构(操作完以后可以blur一下)\n  在进行阙值分割前对图像进行模糊处理(图像处理领域好像叫滤波?)再分割貌似有更好的效果\n  挑战: 验证码识别\n  相关 无\n源 主要是滑块的应用\n// OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; Mat structs; Mat imgIn, imgOut; const int MAXSIZE = 30; int size_ = 0; void Graph(int,void*); int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ //VideoCapture cap; \t//cap = VideoCapture(0); \t//Mat cap0; \t//VideoCapture(0) \u0026gt;\u0026gt; cap0; \t//imshow(\u0026#34;test\u0026#34;, cap0);  imgIn = imread(\u0026#34;D:/WorkSpace/Projects/OpenCV学习/ImageHub/Code1.png\u0026#34;, IMREAD_GRAYSCALE); if (imgIn.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG...\u0026#34; \u0026lt;\u0026lt; endl; return -1; } //imgIn = cap0.clone(); \t//cvtColor(imgIn, imgIn, COLOR_BGR2GRAY); \t//imshow(\u0026#34;test\u0026#34;, imgIn);  medianBlur(imgIn, imgIn, 5); //threshold(~imgIn, imgIn, 0, 255, THRESH_OTSU); \tadaptiveThreshold(~imgIn, imgIn, 255, ADAPTIVE_THRESH_GAUSSIAN_C, THRESH_BINARY, 33, -10); imgOut = imgIn.clone(); /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ namedWindow(\u0026#34;output\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;output\u0026#34;, imgOut); createTrackbar(\u0026#34;Kern Size\u0026#34;, \u0026#34;output\u0026#34;, \u0026amp;size_, MAXSIZE, Graph);\t//这个函数调用的方法非常奇特我搞不懂为什么,前两句是为了初始化窗口↑,注意最后一个参数虽然是函数但是不用括号  /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ //namedWindow(\u0026#34;input\u0026#34;, WINDOW_AUTOSIZE); \t//imshow(\u0026#34;input\u0026#34;, imgIn); \t//namedWindow(\u0026#34;output2\u0026#34;, WINDOW_AUTOSIZE); \t//imshow(\u0026#34;output2\u0026#34;, imgOut2); \t//namedWindow(\u0026#34;output3\u0026#34;, WINDOW_AUTOSIZE); \t//imshow(\u0026#34;output3\u0026#34;, imgOut3); \t//namedWindow(\u0026#34;output4\u0026#34;, WINDOW_AUTOSIZE); \t//imshow(\u0026#34;output4\u0026#34;, imgOut4);  //imwrite(\u0026#34;D:/Download/Family2020_Final.jpg\u0026#34;, imgOut); \t//cout \u0026lt;\u0026lt; \u0026#34;Mat=\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl;  /****************************************\t图像输出\t****************************************************/ waitKey(0); return 0; } void Graph(int, void*) {\t//注意书写格式,虽然我不知道为什么  int s = size_ * 2 + 1 ; structs = getStructuringElement(MORPH_RECT, Size(s, s), Point(-1, -1)); //erode(imgIn, imgOut, structs); \t//dilate(imgOut, imgOut, structs);  morphologyEx(imgIn, imgOut, MORPH_GRADIENT, structs); imshow(\u0026#34;output\u0026#34;, imgOut); return; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E5%BD%A2%E6%80%81%E5%AD%A6%E6%93%8D%E4%BD%9C/","summary":"相关函数 getStructuringElement(int shape, Size ksize ,Point anchor);注意size还是要奇数 dilate(src, dst, kernel);膨胀 erode(src, dst, kernel);腐蚀 creatTrackbar();创建滑块,比较实用,但我搞不懂 morphologyEX();形态学操作 adaptiveThreshold(); threshold(); //大津法 实现   膨胀\n  腐蚀\n  开操作\n  形态学梯度\n  提取垂直或水平的线(使用水平或竖直的结构体)\n  二值化\n  对图像取反(用~)\n  笔记   opencv结构元素获取(getStructuringElement)我理解是类似卷积核的东西\n  膨胀:区域最大值覆盖中心值\n  腐蚀:区域最小值覆盖中心值\n  开操作:先腐蚀后膨胀,去掉小的对象\n  闭操作:先膨胀后腐蚀,填充小的洞\n  形态学梯度可以方便得提取边线\n  提取垂直或水平的线思路: 使用特殊的结构体来提取特殊的结构,比如一条横线进行开操作就可以提取出横线结构(操作完以后可以blur一下)\n  在进行阙值分割前对图像进行模糊处理(图像处理领域好像叫滤波?)再分割貌似有更好的效果\n  挑战: 验证码识别","title":"[CV] 形态学操作"},{"content":"相关函数 blur();\t//均值模糊 GaussianBlur();\t//高斯模糊 medianBlur();\t//中值滤波 bilateralFilter()\t//双边滤波 实现   模糊\n 均值滤波 高斯滤波 中值滤波 双边滤波    笔记  高斯滤波是通过高斯函数也就是正态分布来给mask权重 sigma越大正态分布上表现就是越平滑    中值滤波是统计排序滤波器,对椒盐噪声有很好的抑制作用\n  注意区分中值和均值\n  高斯模糊没有考虑像素值的差异,会导致边缘还是不那么清晰\n  引入空间域核与值域核考虑,空间域就相当于普通的高斯滤波,根据相邻距离决定权重,而值域核是由目标像素值与中心像素值差来给定权重\n  简单来说就是双边模糊对高斯模糊来说多了一层mask,这层mask不是根据像素空间位置来给定权重的,而是根据像素与中心像素值之差得出\n  双边滤波可以磨皮(\n  剩下的看注释\n  相关 无\n源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread(\u0026#34;Test.jpg\u0026#34;); if (imgIn.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG...\u0026#34; \u0026lt;\u0026lt; endl; return -1; } imgOut = imgIn.clone(); /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ //blur(imgIn, imgOut, Size(9, 9), Point(-1, -1));\t//均值模糊  Mat imgOut2; //double sigma = 3; \t//GaussianBlur(imgIn, imgOut2, Size(9,9), sigma, sigma);\t//高斯模糊  Mat imgOut3; //medianBlur(imgIn, imgOut3, 9);\t//中值滤波  Mat imgOut4; bilateralFilter(imgIn, imgOut, 15, 30.0, 30.0); bilateralFilter(imgIn, imgOut2, 30, 30.0, 30.0);\t//在sigmaColor很大的情况下,修改sigmaSpace效果很小 \tbilateralFilter(imgIn, imgOut3, 50, 30.0, 30.0);\t//sigmaColor越大,色块化越严重 \tbilateralFilter(imgIn, imgOut4, 100, 30.0, 30.0);\t//范围d越大,柔化越明显  /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ namedWindow(\u0026#34;input\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;input\u0026#34;, imgIn); namedWindow(\u0026#34;output\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;output\u0026#34;, imgOut); namedWindow(\u0026#34;output2\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output2\u0026#34;, imgOut2); namedWindow(\u0026#34;output3\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output3\u0026#34;, imgOut3); namedWindow(\u0026#34;output4\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output4\u0026#34;, imgOut4); //imwrite(\u0026#34;D:/Download/Family2020_Final.jpg\u0026#34;, imgOut); \t//cout \u0026lt;\u0026lt; \u0026#34;Mat=\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl;  /****************************************\t图像输出\t****************************************************/ waitKey(0); return 0; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread(\u0026#34;Test.jpg\u0026#34;); if (imgIn.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG...\u0026#34; \u0026lt;\u0026lt; endl; return -1; } imgOut = imgIn.clone(); /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ //blur(imgIn, imgOut, Size(9, 9), Point(-1, -1));\t//均值模糊  Mat imgOut2; //double sigma = 3; \t//GaussianBlur(imgIn, imgOut2, Size(9,9), sigma, sigma);\t//高斯模糊  Mat imgOut3; //medianBlur(imgIn, imgOut3, 9);\t//中值滤波  Mat imgOut4; bilateralFilter(imgIn, imgOut, 15, 30.0, 30.0); bilateralFilter(imgIn, imgOut2, 30, 30.0, 30.0);\t//在sigmaColor很大的情况下,修改sigmaSpace效果很小 \tbilateralFilter(imgIn, imgOut3, 50, 30.0, 30.0);\t//sigmaColor越大,色块化越严重 \tbilateralFilter(imgIn, imgOut4, 100, 30.0, 30.0);\t//范围d越大,柔化越明显  /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ namedWindow(\u0026#34;input\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;input\u0026#34;, imgIn); namedWindow(\u0026#34;output\u0026#34;, WINDOW_NORMAL); imshow(\u0026#34;output\u0026#34;, imgOut); namedWindow(\u0026#34;output2\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output2\u0026#34;, imgOut2); namedWindow(\u0026#34;output3\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output3\u0026#34;, imgOut3); namedWindow(\u0026#34;output4\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output4\u0026#34;, imgOut4); //imwrite(\u0026#34;D:/Download/Family2020_Final.jpg\u0026#34;, imgOut); \t//cout \u0026lt;\u0026lt; \u0026#34;Mat=\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl;  /****************************************\t图像输出\t****************************************************/ waitKey(0); return 0; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E5%90%84%E7%B1%BB%E6%A8%A1%E7%B3%8A/","summary":"相关函数 blur();\t//均值模糊 GaussianBlur();\t//高斯模糊 medianBlur();\t//中值滤波 bilateralFilter()\t//双边滤波 实现   模糊\n 均值滤波 高斯滤波 中值滤波 双边滤波    笔记  高斯滤波是通过高斯函数也就是正态分布来给mask权重 sigma越大正态分布上表现就是越平滑    中值滤波是统计排序滤波器,对椒盐噪声有很好的抑制作用\n  注意区分中值和均值\n  高斯模糊没有考虑像素值的差异,会导致边缘还是不那么清晰\n  引入空间域核与值域核考虑,空间域就相当于普通的高斯滤波,根据相邻距离决定权重,而值域核是由目标像素值与中心像素值差来给定权重\n  简单来说就是双边模糊对高斯模糊来说多了一层mask,这层mask不是根据像素空间位置来给定权重的,而是根据像素与中心像素值之差得出\n  双边滤波可以磨皮(\n  剩下的看注释\n  相关 无\n源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread(\u0026#34;Test.","title":"[CV] 各类模糊"},{"content":"相关函数 mat.at\u0026lt;xxx\u0026gt; bitwise_not();//反色 src.convertTo();//通道转换  addWeighted()//图像混合加权相加,大小类型必须一致 multiply()//图像相乘  Mat::zeros cv:point cv:scalar line(); cv:rect rectangle(); 实现  对像素的操作 图像混合 对比度和亮度调节 几何绘制(人脸追踪框可能)  笔记  通过权重相加函数实现图像混合效果  addWeighted()  对比度和亮度调节的实现思想  像素值相乘(对比度实现,因为拉大了数值差) 像素值加常数(亮度实现) 公式:g(x,y) = alpha * f(x,y) + beta    相关 无\n源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread(\u0026#34;Test.jpg\u0026#34;); if (imgIn.empty()) { cout \u0026lt;\u0026lt; \u0026#34;Can not open this IMG...\u0026#34; \u0026lt;\u0026lt; endl; return -1; } imgOut = imgIn.clone(); /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ //cout \u0026lt;\u0026lt; imgOut.at\u0026lt;Vec3b\u0026gt;(20, 20) \u0026lt;\u0026lt; endl; \t//printf(\u0026#34;%d\\n\u0026#34;, imgOut.at\u0026lt;Vec3b\u0026gt;(20, 20)[0]);  bitwise_not(imgIn, imgOut);\t//图像混合 \tMat output(imgIn.size(), imgIn.type()); addWeighted(imgIn, 0.6, imgOut, 0.4, 0.0, output); Rect pos(200, 200, 200, 200);\t//画框 \trectangle(output, pos, Scalar(255, 0, 0), 1, LINE_8, 0); int ix, iy; //int col = imgIn.cols; \t//int row = imgIn.rows; \tfor (ix = 0; ix \u0026lt; imgIn.cols; ix++) { for (iy = 0; iy \u0026lt; imgIn.rows; iy++) { for (int channal = 0; channal \u0026lt; 3; channal++) { output.at\u0026lt;Vec3b\u0026gt;(ix, iy)[channal] = saturate_cast\u0026lt;uchar\u0026gt;(output.at\u0026lt;Vec3b\u0026gt;(ix, iy)[channal] * 3 - 190);\t//对每个像素的通道进行计算,三倍单位对比度,-190等亮度 \t} } } /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ namedWindow(\u0026#34;input\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;input\u0026#34;, imgIn); namedWindow(\u0026#34;output\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output\u0026#34;, output); //cout \u0026lt;\u0026lt; \u0026#34;Mat=\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl;  /****************************************\t图像输出\t****************************************************/ waitKey(0); return 0; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E5%9B%BE%E5%83%8F%E6%B7%B7%E5%90%88_%E4%BA%AE%E5%BA%A6%E5%AF%B9%E6%AF%94%E5%BA%A6_%E5%87%A0%E4%BD%95%E7%BB%98%E5%88%B6/","summary":"相关函数 mat.at\u0026lt;xxx\u0026gt; bitwise_not();//反色 src.convertTo();//通道转换  addWeighted()//图像混合加权相加,大小类型必须一致 multiply()//图像相乘  Mat::zeros cv:point cv:scalar line(); cv:rect rectangle(); 实现  对像素的操作 图像混合 对比度和亮度调节 几何绘制(人脸追踪框可能)  笔记  通过权重相加函数实现图像混合效果  addWeighted()  对比度和亮度调节的实现思想  像素值相乘(对比度实现,因为拉大了数值差) 像素值加常数(亮度实现) 公式:g(x,y) = alpha * f(x,y) + beta    相关 无\n源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread(\u0026#34;Test.","title":"[CV] 图像混合-亮度对比度-几何绘制"},{"content":"完成  统计时间 色彩空间转换 线性滤波器使用 图像读取写入plus 图像指针  相关函数 gettickcount();//获取时钟 mat.ptr\u0026lt;uchar\u0026gt;;//获取图像指针 saturate_cast\u0026lt;uchar\u0026gt;;//防溢出函数 filter2D;//线性滤波器 imread(); imwrite(); cvtColer();//色彩空间转换 实现 使用卷积加强图像对比度\n笔记   关于imread和imwrite的地址传入\n可以使用c++的string或cv自己的String实现,使用cin读入地址\n  源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; void colChange(Mat \u0026amp;iImg, Mat \u0026amp;oImg) {\t//色彩空间变换 \tcvtColor(iImg, oImg, COLOR_BGR2GRAY); return; } void addFilter(Mat \u0026amp;iImg, Mat \u0026amp;oImg,const Mat filter) {\t//添加线性滤波器 \tfilter2D(iImg, oImg, -1, filter); return; } int main(int argc, char** argv)\t//实现读取摄像头内容输出加强对比度,并统计每帧处理时间 { VideoCapture cap(0); if (!cap.isOpened()) return -1; //namedWindow(\u0026#34;frame\u0026#34;, WINDOW_AUTOSIZE); \t//while(1) \t/*{ Mat frameIn; cap \u0026gt;\u0026gt; frameIn;*/ //\timshow(\u0026#34;frame\u0026#34;, frameIn); \t//\tif (waitKey(30) \u0026gt;= 0) \t//\tbreak; \t//}  Mat iImg; Mat oImg; Mat filter ; String path1; string path2; //cin \u0026gt;\u0026gt; path1; \t//path2 = path1;  //iImg = imread(path2); \t//if (iImg.empty()) { \t//\tprintf(\u0026#34;Can not read img...\u0026#34;); \t//\treturn -1; \t//} \twhile (1) { cap \u0026gt;\u0026gt; iImg; oImg = Mat::zeros(iImg.size(), iImg.type());\t//创建零矩阵 \tfilter = (Mat_\u0026lt;char\u0026gt;(3, 3) \u0026lt;\u0026lt; 0, -1, 0, -1, 5, -1, 0, -1, 0);\t//定义卷积核  double tCount = 0; tCount = getTickCount(); //colChange(iImg, oImg); \taddFilter(iImg, oImg, filter); //iImg = imread(\u0026#34;Test.jpg\u0026#34;, IMREAD_GRAYSCALE); \t//oImg = iImg;  double tSum = 0; tSum = (getTickCount() - tCount) / getTickFrequency(); printf(\u0026#34;Time consume %.4f\u0026#34;, tSum); //imwrite(\u0026#34;layout.jpg\u0026#34;, oImg); \tnamedWindow(\u0026#34;imput\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;imput\u0026#34;, iImg); namedWindow(\u0026#34;layout\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;layout\u0026#34;, oImg); if (waitKey(30) \u0026gt;= 0) { break; }; } return 0; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 相关 无\n","permalink":"https://dynais.github.io/code/posts/code.cv.%E7%BA%BF%E6%80%A7%E6%BB%A4%E6%B3%A2%E5%99%A8_%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4%E8%BD%AC%E6%8D%A2/","summary":"完成  统计时间 色彩空间转换 线性滤波器使用 图像读取写入plus 图像指针  相关函数 gettickcount();//获取时钟 mat.ptr\u0026lt;uchar\u0026gt;;//获取图像指针 saturate_cast\u0026lt;uchar\u0026gt;;//防溢出函数 filter2D;//线性滤波器 imread(); imwrite(); cvtColer();//色彩空间转换 实现 使用卷积加强图像对比度\n笔记   关于imread和imwrite的地址传入\n可以使用c++的string或cv自己的String实现,使用cin读入地址\n  源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; void colChange(Mat \u0026amp;iImg, Mat \u0026amp;oImg) {\t//色彩空间变换 \tcvtColor(iImg, oImg, COLOR_BGR2GRAY); return; } void addFilter(Mat \u0026amp;iImg, Mat \u0026amp;oImg,const Mat filter) {\t//添加线性滤波器 \tfilter2D(iImg, oImg, -1, filter); return; } int main(int argc, char** argv)\t//实现读取摄像头内容输出加强对比度,并统计每帧处理时间 { VideoCapture cap(0); if (!","title":"[CV] 线性滤波器-色彩空间转换"},{"content":"完成   实现静态图片读取功能\n  复习cmd指令\n  学习了在cmd下使用exe文件\n  实现 相关 ","permalink":"https://dynais.github.io/code/posts/code.cv.%E5%9B%BE%E5%83%8F%E8%AF%BB%E5%8F%96/","summary":"完成   实现静态图片读取功能\n  复习cmd指令\n  学习了在cmd下使用exe文件\n  实现 相关 ","title":"[CV] 图像读取"},{"content":"记了一些常用的CMD命令\n 进入某个盘 进入d盘\nD: 进入F盘\nF: 查看目录文件 查看当前目录下的文件，类似于linux下的ls\ndir 如果是需要查看隐藏文件的或者更多操作的话，可以使用\ndir /? 来查看其它用法\n执行exe文件 直接进入路径输入exe文件名+参数就行\n创建目录和删除目录 创建目录\nmd 目录名（文件夹） 删除目录\nrd 目录名（文件夹） 查看本机ip ipconfig 清除屏幕 cls 类似于linux下的clear\n复制文件 copy 路径\\文件名 路径\\文件名 ：把一个文件拷贝到另一个地方。 移动文件 move 路径\\文件名 路径\\文件名 ：把一个文件移动（就是剪切+复制）到另一个地方。 删除文件 这个是专门删除文件的，不能删除文件夹\ndel 文件名 ping 用来测试网络是否畅通\nping ip(主机名)  查看cmd下的命令 使用help命令，查看所有的dos命令 找到命令之后，使用 命令+ /?来查看该命令下的其他属性 ","permalink":"https://dynais.github.io/code/posts/code.cmd%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%9F%A5%E6%89%BE%E8%A1%A8/","summary":"记了一些常用的CMD命令\n 进入某个盘 进入d盘\nD: 进入F盘\nF: 查看目录文件 查看当前目录下的文件，类似于linux下的ls\ndir 如果是需要查看隐藏文件的或者更多操作的话，可以使用\ndir /? 来查看其它用法\n执行exe文件 直接进入路径输入exe文件名+参数就行\n创建目录和删除目录 创建目录\nmd 目录名（文件夹） 删除目录\nrd 目录名（文件夹） 查看本机ip ipconfig 清除屏幕 cls 类似于linux下的clear\n复制文件 copy 路径\\文件名 路径\\文件名 ：把一个文件拷贝到另一个地方。 移动文件 move 路径\\文件名 路径\\文件名 ：把一个文件移动（就是剪切+复制）到另一个地方。 删除文件 这个是专门删除文件的，不能删除文件夹\ndel 文件名 ping 用来测试网络是否畅通\nping ip(主机名)  查看cmd下的命令 使用help命令，查看所有的dos命令 找到命令之后，使用 命令+ /?来查看该命令下的其他属性 ","title":"CMD常用命令查找表"},{"content":"完成  自己创建指定mat 用算法创建mat 克隆mat  相关函数 mat.clone(); mat.copyTo(); (1) Mat::Mat() (2) Mat::Mat(int rows, int cols, int type) (3) Mat::Mat(Size size, int type) (4) Mat::Mat(int rows, int cols, int type, constScalar\u0026amp; s) (5) Mat::Mat(Size size, int type, constScalar\u0026amp; s) (6) Mat::Mat(const Mat\u0026amp; m) mat.ptr\u0026lt;uchar\u0026gt; 实现 使用函数克隆一个一样的图\n使用函数创建空白图(全0和全255)\n使空白图成为渐变灰度图\n使空白图成为渐变色度图\n笔记   关于clone() \\ copyTo() 和 直接赋值的区别\nclone和copyTo是直接重新创建一个新的内存空间\n而直接赋值则是一个类似传递的作用,这样直接修改B的内容也会影响到A\n  区分Scalar和Vec3b\nScala指标量,Vec指向量\nVec类似于C++中的Vector 也就是说可用{}赋值\nScala我现在只知道在初始化中可用\n  相关 无\n源 // OpenCV_Template.cpp : 此文件包含 \u0026#34;main\u0026#34; 函数。程序执行将在此处开始并结束。 //  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include\u0026lt;opencv2\\opencv.hpp\u0026gt; using namespace std; using namespace cv; int main(int argc, char** argv){ /****************************************\t初始化\t****************************************************/ Mat imgIn, imgOut; Mat mask; imgIn = imread(\u0026#34;Test.jpg\u0026#34;); //imgOut = imgIn;\t//证实了这种复制方法只是把in的地址给了out,如果改变out内容,则in也会改变 \timgIn.copyTo(imgOut);\t//这种方式会分配新的内存,且会检测需不需要分配新地址 \t//imgOut = imgIn.clone();\t//这种方法会分配新的内存,且一定会分配新地址  /****************************************\t初始化\t****************************************************/ /****************************************\t图像操作\t****************************************************/ int cont = 0; int i, j; //创建指定Mat \t//imgOut = Mat(100, 100, CV_8UC3, Scalar(0, 0, 0));\t//创建全黑图像 \t//imgOut = Mat(100, 100, CV_8UC3, Scalar(255, 255, 255));\t//创建全白图像  //像素归零 \t//for (j = 0; j \u0026lt; imgOut.rows; j++) { \t//\tfor (i = 0; i \u0026lt; imgOut.cols*3; i++) { \t//\timgOut.at\u0026lt;uchar\u0026gt;(j, i) = 0;\t//at方法相当于在操作矩阵,对于这种三个像素一组的矩阵操作不方便,也是col要乘三的原因; \t//\t} \t//}  //算法创建渐变灰度图(at方法)(防溢出) \t//imgOut = Mat(500, 255, CV_8UC1); \t//uchar gray = 0; \t//for (j = 0; j \u0026lt; imgOut.rows; j++) { \t//\tgray = saturate_cast\u0026lt;uchar\u0026gt;(j); \t//\tfor (i = 0; i \u0026lt; imgOut.cols; i++) { \t//\timgOut.at\u0026lt;uchar\u0026gt;(j, i) = gray; \t//\t} \t//}  //算法创建渐变灰度图(ptr方法)(防溢出)(单通道图像操作) \t//imgOut = Mat(500, 255, CV_8UC1); \t//uchar gray = 0; \t//uchar* index; \t//for (j = 0; j \u0026lt; imgOut.rows; j++) { \t//\tgray = saturate_cast\u0026lt;uchar\u0026gt;(j); \t//\tfor (i = 0; i \u0026lt; imgOut.cols; i++) { \t//\tindex = imgOut.ptr\u0026lt;uchar\u0026gt;(j, i); \t//\t*index = gray; \t//\t} \t//}  //算法创建渐变灰度图(ptr方法)(防溢出)(多通道图像操作) \timgOut = Mat(255, 255, CV_8UC3, Scalar(0,0,0)); Vec3b color = {0,0,0};\t//与c++的vector类似,可以通用? \tVec3b* index; for (j = 0; j \u0026lt; imgOut.rows; j++) { for (i = 0; i \u0026lt; imgOut.cols; i++) { color = { saturate_cast\u0026lt;uchar\u0026gt;(j),saturate_cast\u0026lt;uchar\u0026gt;(i) ,0 }; index = imgOut.ptr\u0026lt;Vec3b\u0026gt;(j, i); *index = color; } } /****************************************\t图像操作\t****************************************************/ /****************************************\t图像输出\t****************************************************/ namedWindow(\u0026#34;input\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;input\u0026#34;, imgIn); namedWindow(\u0026#34;output\u0026#34;, WINDOW_AUTOSIZE); imshow(\u0026#34;output\u0026#34;, imgOut); //cout \u0026lt;\u0026lt; \u0026#34;Mat=\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; imgOut \u0026lt;\u0026lt; endl;  /****************************************\t图像输出\t****************************************************/ waitKey(0); return 0; } // 运行程序: Ctrl + F5 或调试 \u0026gt;“开始执行(不调试)”菜单 // 调试程序: F5 或调试 \u0026gt;“开始调试”菜单  // 入门使用技巧: // 1. 使用解决方案资源管理器窗口添加/管理文件 // 2. 使用团队资源管理器窗口连接到源代码管理 // 3. 使用输出窗口查看生成输出和其他消息 // 4. 使用错误列表窗口查看错误 // 5. 转到“项目”\u0026gt;“添加新项”以创建新的代码文件，或转到“项目”\u0026gt;“添加现有项”以将现有代码文件添加到项目 // 6. 将来，若要再次打开此项目，请转到“文件”\u0026gt;“打开”\u0026gt;“项目”并选择 .sln 文件 ","permalink":"https://dynais.github.io/code/posts/code.cv.mat%E6%93%8D%E4%BD%9C/","summary":"完成  自己创建指定mat 用算法创建mat 克隆mat  相关函数 mat.clone(); mat.copyTo(); (1) Mat::Mat() (2) Mat::Mat(int rows, int cols, int type) (3) Mat::Mat(Size size, int type) (4) Mat::Mat(int rows, int cols, int type, constScalar\u0026amp; s) (5) Mat::Mat(Size size, int type, constScalar\u0026amp; s) (6) Mat::Mat(const Mat\u0026amp; m) mat.ptr\u0026lt;uchar\u0026gt; 实现 使用函数克隆一个一样的图\n使用函数创建空白图(全0和全255)\n使空白图成为渐变灰度图\n使空白图成为渐变色度图\n笔记   关于clone() \\ copyTo() 和 直接赋值的区别\nclone和copyTo是直接重新创建一个新的内存空间\n而直接赋值则是一个类似传递的作用,这样直接修改B的内容也会影响到A\n  区分Scalar和Vec3b\nScala指标量,Vec指向量\nVec类似于C++中的Vector 也就是说可用{}赋值\nScala我现在只知道在初始化中可用\n  相关 无","title":"[CV] Mat操作"}]