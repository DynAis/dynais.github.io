<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>使用差分散列的重复图片检测 | DynAis</title><meta name=keywords content="opencv,散列,difference hashing,hash"><meta name=description content="关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.
而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:
 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:
 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:
 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:
https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/
https://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb
  前言:
为什么要删去数据集中重复的图片?
Having duplicate images in your dataset creates a problem for two reasons:
 It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize."><meta name=author content><link rel=canonical href=https://dynais.github.io/posts/nt-ocpy-%E4%BD%BF%E7%94%A8%E5%B7%AE%E5%88%86%E6%95%A3%E5%88%97%E6%A3%80%E6%B5%8B%E9%87%8D%E5%A4%8D%E5%9B%BE%E7%89%87/><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dynais.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dynais.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dynais.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dynais.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dynais.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="使用差分散列的重复图片检测"><meta property="og:description" content="关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.
而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:
 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:
 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:
 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:
https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/
https://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb
  前言:
为什么要删去数据集中重复的图片?
Having duplicate images in your dataset creates a problem for two reasons:
 It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize."><meta property="og:type" content="article"><meta property="og:url" content="https://dynais.github.io/posts/nt-ocpy-%E4%BD%BF%E7%94%A8%E5%B7%AE%E5%88%86%E6%95%A3%E5%88%97%E6%A3%80%E6%B5%8B%E9%87%8D%E5%A4%8D%E5%9B%BE%E7%89%87/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-04-22T00:00:00+00:00"><meta property="article:modified_time" content="2020-04-22T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="使用差分散列的重复图片检测"><meta name=twitter:description content="关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.
而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:
 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:
 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:
 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:
https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/
https://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb
  前言:
为什么要删去数据集中重复的图片?
Having duplicate images in your dataset creates a problem for two reasons:
 It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dynais.github.io/posts/"},{"@type":"ListItem","position":2,"name":"使用差分散列的重复图片检测","item":"https://dynais.github.io/posts/nt-ocpy-%E4%BD%BF%E7%94%A8%E5%B7%AE%E5%88%86%E6%95%A3%E5%88%97%E6%A3%80%E6%B5%8B%E9%87%8D%E5%A4%8D%E5%9B%BE%E7%89%87/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"使用差分散列的重复图片检测","name":"使用差分散列的重复图片检测","description":"关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.\n而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:\n 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:\n 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:\n 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:\nhttps://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/\nhttps://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb\n  前言:\n为什么要删去数据集中重复的图片?\nHaving duplicate images in your dataset creates a problem for two reasons:\n It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize.","keywords":["opencv","散列","difference hashing","hash"],"articleBody":"关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.\n而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:\n 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:\n 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:\n 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  Detect and remove duplicate images from a dataset for deep learning  文章链接:\nhttps://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/\nhttps://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb\n  前言:\n为什么要删去数据集中重复的图片?\nHaving duplicate images in your dataset creates a problem for two reasons:\n It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates It hurts the ability of your model to generalize to new images outside of what it was trained on  Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize.\n 一. 关于图像散列值 关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.\n而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:\n 视觉上相差不大的图片, 他们的Hash值也应该相同 这个Hash计算需要快, 因为有时候数据量会很大  那么我们有以下几个Hash函数的选择:\n 差分散列(difference hashing) md5 sha-1  最终我们选择了差分散列的方法, 有以下的原因:\n 差分散列速度很快, 计算量小 对于肉眼相差不大的图片, 差分散列可以得出相似的值 md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)  二. 我们所需的步骤 1. Convert to grayscale 转灰度 在这里, 颜色信息对于判定两张图是否相同其实并不是很重要, 所以将三通道转为一个通道可以很好的减少我们的工作量\n2. Resize 忽略长宽比缩放 这是为了得到一个合适的大小, 以便符合后续的Hash计算, 所有需要保证所有的图片具有相同的大小尺寸, 这牵扯到差分散列的工作原理, 这会在后面解释\n在这里, 我们需要将原图缩放到只有$ 9 * 8 $大小\n3. Compute the difference 计算差分(梯度) 差分散列算法, 故名思与需要计算差分信息, 在图片里, 指的就是相邻像素之间的梯度.\n好了, 这就是之前我们为什么需要 $ 9 * 8 $ 像素的原因了\n因为我们需要得到的是一个64位的二进制信息, 而 $8 * 8=64$ , 由于是计算差分(梯度), 所以必然需要九行\n需要注意: 这里虽然说是差分, 但实际上使用的是非常简化的版本: 但前一个像素大于后一个像素时, 给出一个$1$, 否则, 给出一个$0$, 也就是说, 可以看作只提取梯度的正负符号信息, 公式为\n​\t$P[x]  P[x + 1] = 1 else 0$\n那么现在我们得到了一个64bit的值, 接下来就对他进行Hash计算\n4. Build the hash 计算散列值 def dhash(image, hashSize=8): \t# convert the image to grayscale and resize the grayscale image, \t# adding a single column (width) so we can compute the horizontal \t# gradient \tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \tresized = cv2.resize(gray, (hashSize + 1, hashSize))  \t# compute the (relative) horizontal gradient between adjacent \t# column pixels \tdiff = resized[:, 1:]  resized[:, :-1]  \t# convert the difference image to a hash and return it \treturn sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v]) 5. 初始化字典, 寻找重复并输出 略\n","wordCount":"307","inLanguage":"en","datePublished":"2020-04-22T00:00:00Z","dateModified":"2020-04-22T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://dynais.github.io/posts/nt-ocpy-%E4%BD%BF%E7%94%A8%E5%B7%AE%E5%88%86%E6%95%A3%E5%88%97%E6%A3%80%E6%B5%8B%E9%87%8D%E5%A4%8D%E5%9B%BE%E7%89%87/"},"publisher":{"@type":"Organization","name":"DynAis","logo":{"@type":"ImageObject","url":"https://dynais.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dynais.github.io/ accesskey=h title="DynAis (Alt + H)">DynAis</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>使用差分散列的重复图片检测</h1><div class=post-meta><span title="2020-04-22 00:00:00 +0000 UTC">April 22, 2020</span></div></header><div class=post-content><p>关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.</p><p>而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:</p><ul><li>视觉上相差不大的图片, 他们的Hash值也应该相同</li><li>这个Hash计算需要快, 因为有时候数据量会很大</li></ul><p>那么我们有以下几个Hash函数的选择:</p><ul><li><strong>差分散列(<em>difference hashing</em>)</strong></li><li><strong>md5</strong></li><li><strong>sha-1</strong></li></ul><p>最终我们选择了<strong>差分散列</strong>的方法, 有以下的原因:</p><ol><li>差分散列速度很快, 计算量小</li><li>对于肉眼相差不大的图片, 差分散列可以得出相似的值</li><li>md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)</li></ol><h2 id=detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning>Detect and remove duplicate images from a dataset for deep learning<a hidden class=anchor aria-hidden=true href=#detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning>#</a></h2><blockquote><p>文章链接:</p><p><a href=https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/>https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/</a></p><p><a href="https://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb">https://www.pyimagesearch.com/2020/04/20/detect-and-remove-duplicate-images-from-a-dataset-for-deep-learning/?__s=bnfo5g8qgjr6gztmvjlb</a></p></blockquote><blockquote><p>前言:</p><p>为什么要删去数据集中重复的图片?</p><p><em>Having duplicate images in your dataset creates a problem for two reasons:</em></p><ol><li><em>It introduces bias into your dataset, giving your deep neural network additional opportunities to learn patterns specific to the duplicates</em></li><li><em>It hurts the ability of your model to generalize to new images outside of what it was trained on</em></li></ol><p><em>Take the time to remove duplicates from your image dataset so you don’t accidentally introduce bias or hurt the ability of your model to generalize.</em></p></blockquote><h2 id=一-关于图像散列值>一. 关于图像散列值<a hidden class=anchor aria-hidden=true href=#一-关于图像散列值>#</a></h2><p>关于散列(Hash), 网上的介绍有很多,这里就不费力介绍.</p><p>而对于这个具体的项目要求来说, 我们所做的只是需要把一个图像转换为一个Hash值, 然后储存到字典中. 并且有一下要求:</p><ul><li>视觉上相差不大的图片, 他们的Hash值也应该相同</li><li>这个Hash计算需要快, 因为有时候数据量会很大</li></ul><p>那么我们有以下几个Hash函数的选择:</p><ul><li><strong>差分散列(<em>difference hashing</em>)</strong></li><li><strong>md5</strong></li><li><strong>sha-1</strong></li></ul><p>最终我们选择了<strong>差分散列</strong>的方法, 有以下的原因:</p><ol><li>差分散列速度很快, 计算量小</li><li>对于肉眼相差不大的图片, 差分散列可以得出相似的值</li><li>md5 和 sha-1 只要有一点变化, 输出值就会完全改变(这本来很好, 但在这里非常不好!)</li></ol><h2 id=二-我们所需的步骤>二. 我们所需的步骤<a hidden class=anchor aria-hidden=true href=#二-我们所需的步骤>#</a></h2><h3 id=1-convert-to-grayscale-转灰度>1. Convert to grayscale 转灰度<a hidden class=anchor aria-hidden=true href=#1-convert-to-grayscale-转灰度>#</a></h3><p>在这里, 颜色信息对于判定两张图是否相同其实并不是很重要, 所以将三通道转为一个通道可以很好的减少我们的工作量</p><h3 id=2-resize-忽略长宽比缩放>2. Resize 忽略长宽比缩放<a hidden class=anchor aria-hidden=true href=#2-resize-忽略长宽比缩放>#</a></h3><p>这是为了得到一个合适的大小, 以便符合后续的Hash计算, 所有需要保证所有的图片具有相同的大小尺寸, 这牵扯到差分散列的工作原理, 这会在后面解释</p><p>在这里, 我们需要将原图缩放到只有$ 9 * 8 $大小</p><h3 id=3-compute-the-difference-计算差分梯度>3. Compute the difference 计算差分(梯度)<a hidden class=anchor aria-hidden=true href=#3-compute-the-difference-计算差分梯度>#</a></h3><p>差分散列算法, 故名思与需要计算差分信息, 在图片里, 指的就是相邻像素之间的梯度.</p><p>好了, 这就是之前我们为什么需要 $ 9 * 8 $ 像素的原因了</p><p>因为我们需要得到的是一个64位的二进制信息, 而 $8 * 8=64$ , 由于是计算差分(梯度), 所以必然需要九行</p><p><strong>需要注意:</strong> 这里虽然说是差分, 但实际上使用的是非常简化的版本: 但前一个像素大于后一个像素时, 给出一个$1$, 否则, 给出一个$0$, 也就是说, 可以看作只提取梯度的正负符号信息, 公式为</p><p>​ $P[x] > P[x + 1] = 1 else 0$</p><p>那么现在我们得到了一个64bit的值, 接下来就对他进行Hash计算</p><h3 id=4-build-the-hash-计算散列值>4. Build the hash 计算散列值<a hidden class=anchor aria-hidden=true href=#4-build-the-hash-计算散列值>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dhash</span>(image, hashSize<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>):
</span></span><span style=display:flex><span>	<span style=color:#75715e># convert the image to grayscale and resize the grayscale image,</span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># adding a single column (width) so we can compute the horizontal</span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># gradient</span>
</span></span><span style=display:flex><span>	gray <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>cvtColor(image, cv2<span style=color:#f92672>.</span>COLOR_BGR2GRAY)
</span></span><span style=display:flex><span>	resized <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>resize(gray, (hashSize <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, hashSize))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># compute the (relative) horizontal gradient between adjacent</span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># column pixels</span>
</span></span><span style=display:flex><span>	diff <span style=color:#f92672>=</span> resized[:, <span style=color:#ae81ff>1</span>:] <span style=color:#f92672>&gt;</span> resized[:, :<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># convert the difference image to a hash and return it</span>
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>return</span> sum([<span style=color:#ae81ff>2</span> <span style=color:#f92672>**</span> i <span style=color:#66d9ef>for</span> (i, v) <span style=color:#f92672>in</span> enumerate(diff<span style=color:#f92672>.</span>flatten()) <span style=color:#66d9ef>if</span> v])
</span></span></code></pre></div><h3 id=5-初始化字典-寻找重复并输出>5. 初始化字典, 寻找重复并输出<a hidden class=anchor aria-hidden=true href=#5-初始化字典-寻找重复并输出>#</a></h3><p>略</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dynais.github.io/tags/opencv/>OpenCV</a></li><li><a href=https://dynais.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/>数字图像处理</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://dynais.github.io/>DynAis</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>